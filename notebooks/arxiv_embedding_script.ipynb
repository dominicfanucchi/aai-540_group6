{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below install will be necessary in every notebook on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need script to convert to numeric for everything to input into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.36.6)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.237.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.36.6)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.11.1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.115.7)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.23.0)\n",
      "Requirement already satisfied: omegaconf<2.3,>=2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (5.29.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.1.1)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.19)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.34.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.37.0,>=1.36.6->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from omegaconf<2.3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.2.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.10.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.36.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.22.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fastapi->sagemaker) (0.45.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2024.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.17)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn->sagemaker) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Downloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m156.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m166.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m158.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m136.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m167.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m205.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m163.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed huggingface-hub-0.28.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 safetensors-0.5.2 sympy-1.13.1 tokenizers-0.21.0 torch-2.6.0 transformers-4.48.2 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch scikit-learn boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E7usai1XuYe5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/01/25 19:55:42] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/01/25 19:55:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=193827;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=823329;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.image_uris import retrieve\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/01/25 19:55:55] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/01/25 19:55:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=800161;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=500397;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using region: us-east-1\n",
      "USing role: arn:aws:iam::221082214706:role/MYLabRole\n"
     ]
    }
   ],
   "source": [
    "# Setup S3 paths, chunk size, etc.\n",
    "\n",
    "role = \"arn:aws:iam::221082214706:role/MYLabRole\" # Hardcode, maybe avoids errors\n",
    "region = \"us-east-1\"\n",
    "\n",
    "# Boto3 + SageMaker session \n",
    "boto_sess = boto3.Session(region_name=region)\n",
    "session = sagemaker.Session(boto_session=boto_sess)\n",
    "print(f\"Using region: {region}\")\n",
    "print(f\"USing role: {role}\")\n",
    "\n",
    "bucket_name = \"arxiv-project-bucket\"\n",
    "prefix_in = \"processed-data/\"\n",
    "prefix_out = \"processed-data/embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: https://github.com/aws/deep-learning-containers/blob/master/available_images.md#hugging-face-training-containers\n",
    "# If you go to the link, and check huggingface tgraining containers, all require GPU, so set access to GPU use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace DLC for embeddings instead of pip install like data_preprocessing\n",
    "huggingface_image_uri = (\n",
    "    \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:2.1.0-transformers4.36.0-gpu-py310-cu121-ubuntu20.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rest should be similar to preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_processor = ScriptProcessor(\n",
    "    image_uri=huggingface_image_uri,\n",
    "    command=[\"python3\"],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.2xlarge\",  # I set permissions, can probably run on reduced model size\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=20500,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/01/25 19:56:07] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating processing-job with name                                      <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         huggingface-pytorch-training-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-01-19-56-07-321                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/01/25 19:56:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating processing-job with name                                      \u001b]8;id=101545;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=747186;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1575\u001b\\\u001b[2m1575\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         huggingface-pytorch-training-\u001b[1;36m2025\u001b[0m-02-01-19-56-07-321                   \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mCSV chunk files: ['arxiv_preprocessed_part8.csv', 'arxiv_preprocessed_part12.csv', 'arxiv_preprocessed_part13.csv', 'arxiv_preprocessed_part4.csv', 'arxiv_preprocessed_part2.csv', 'arxiv_preprocessed_part6.csv', 'arxiv_preprocessed_part11.csv', 'arxiv_preprocessed_part0.csv', 'arxiv_preprocessed_part5.csv', 'arxiv_preprocessed_part7.csv', 'arxiv_preprocessed_part3.csv', 'arxiv_preprocessed_part1.csv', 'arxiv_preprocessed_part10.csv', 'arxiv_preprocessed_part9.csv']\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part8.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part8.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part8.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part8_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part12.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part12.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part12.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part12_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part13.csv (rows: 47472)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part13.csv: processed 10000 / 47472 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part13.csv: processed 20000 / 47472 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part13.csv: processed 30000 / 47472 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part13.csv: processed 40000 / 47472 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part13.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part13_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part4.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part4.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part4.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part4_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part2.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part2.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part2.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part2_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part6.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part6.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part6.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part6_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part11.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part11.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part11.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part11_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part0.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part0.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part0.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part0_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part5.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part5.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part5.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part5_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part7.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part7.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part7.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part7_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part3.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part3.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part3.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part3_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part1.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part1.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part1.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part1_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part10.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part10.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part10.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part10_embedded.csv\u001b[0m\n",
      "\u001b[34mStart embedding arxiv_preprocessed_part9.csv (rows: 200000)\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 10000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 20000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 30000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 40000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 50000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 60000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 70000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 80000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 90000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 100000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 110000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 120000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 130000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 140000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 150000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 160000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 170000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 180000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 190000 / 200000 rows\u001b[0m\n",
      "\u001b[34m...arxiv_preprocessed_part9.csv: processed 200000 / 200000 rows\u001b[0m\n",
      "\u001b[34mFinished arxiv_preprocessed_part9.csv, wrote embedded file: /opt/ml/processing/output/arxiv_preprocessed_part9_embedded.csv\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run embedding job in .py file containing script logic\n",
    "embedding_processor.run(\n",
    "    code=\"embedding_script.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=f\"s3://{bucket_name}/{prefix_in}\",\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=f\"s3://{bucket_name}/{prefix_out}\"\n",
    "        )\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--input-csv-dir\", \"/opt/ml/processing/input\",\n",
    "        \"--output-csv-dir\", \"/opt/ml/processing/output\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'input-1',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://arxiv-project-bucket/processed-data/',\n",
       "    'LocalPath': '/opt/ml/processing/input',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'code',\n",
       "   'AppManaged': False,\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-221082214706/huggingface-pytorch-training-2025-02-01-19-56-07-321/input/code/embedding_script.py',\n",
       "    'LocalPath': '/opt/ml/processing/input/code',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'output-1',\n",
       "    'S3Output': {'S3Uri': 's3://arxiv-project-bucket/processed-data/embeddings/',\n",
       "     'LocalPath': '/opt/ml/processing/output',\n",
       "     'S3UploadMode': 'EndOfJob'},\n",
       "    'AppManaged': False}]},\n",
       " 'ProcessingJobName': 'huggingface-pytorch-training-2025-02-01-19-56-07-321',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
       "   'InstanceType': 'ml.g4dn.2xlarge',\n",
       "   'VolumeSizeInGB': 30}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 20500},\n",
       " 'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:2.1.0-transformers4.36.0-gpu-py310-cu121-ubuntu20.04',\n",
       "  'ContainerEntrypoint': ['python3',\n",
       "   '/opt/ml/processing/input/code/embedding_script.py'],\n",
       "  'ContainerArguments': ['--input-csv-dir',\n",
       "   '/opt/ml/processing/input',\n",
       "   '--output-csv-dir',\n",
       "   '/opt/ml/processing/output']},\n",
       " 'RoleArn': 'arn:aws:iam::221082214706:role/MYLabRole',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:221082214706:processing-job/huggingface-pytorch-training-2025-02-01-19-56-07-321',\n",
       " 'ProcessingJobStatus': 'Completed',\n",
       " 'ProcessingEndTime': datetime.datetime(2025, 2, 2, 0, 1, 34, tzinfo=tzlocal()),\n",
       " 'ProcessingStartTime': datetime.datetime(2025, 2, 1, 19, 56, 52, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2025, 2, 2, 0, 1, 36, 251000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2025, 2, 1, 19, 56, 7, 781000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '1871e4da-5a89-4aac-b480-9276b4dcf84b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1871e4da-5a89-4aac-b480-9276b4dcf84b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1807',\n",
       "   'date': 'Sun, 02 Feb 2025 00:03:20 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check\n",
    "job_desc = embedding_processor.jobs[-1].describe()\n",
    "job_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L-k07N5uwJd"
   },
   "source": [
    " - Should result in CSV with an additional column abstract_embedding, at s3://my-arxiv-project-bucket/processed-data/embeddings/embeddings.csv."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
